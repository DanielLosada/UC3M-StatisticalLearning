---
title: "Assigment"
output: html_document
date: "2025-02-25"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
install.packages("archive")
install.packages("OpenImageR")
```
```{r}
library(archive)
library(dplyr)

COMPUTE_GRID_SEARCH <- FALSE
```


# Input data

```{r}
# Specify the file path
rar_file <- "Training.rar"

# Extract the contents
#unpacked_files <- archive::archive_extract(rar_file)
try(archive_extract("Training.rar"), silent = TRUE)
```


```{r}
extract_id <- function(filename) {
    matches <- regmatches(basename(filename), regexpr("[0-9]+", basename(filename)))
    return(as.numeric(matches))  # Convert to numeric
}

get_sorted_filenames <- function(){
  # Get all .jpg files
  image_files <- list.files("Training", pattern = "\\.jpg$", full.names = TRUE)
  
  sorted_indices <- order(sapply(image_files, extract_id))
  image_files <- image_files[sorted_indices]
  return(image_files)
}

```


```{r}
# Get all .jpg files in the Training folder
image_files <- get_sorted_filenames()
#Remove the files
#image_files <- image_files[!image_files %in% c("Training/1AT.jpg", "Training/3BT.jpg")]

image_ids <- sapply(image_files, extract_id)

image_rows  <- list()
for (file in image_files) {
  img <- OpenImageR::readImage(file)  # Load image
  
  # Flatten RGB channels and concatenate into a single row
  red <- as.vector(img[,,1])  # Flatten red channel
  green <- as.vector(img[,,2]) # Flatten green channel
  blue <- as.vector(img[,,3])  # Flatten blue channel
  
  # Combine R, G, B into one row and store it
  image_rows[[file]] <- c(red, green, blue)
}

# Convert the list of rows into a matrix
M <- do.call(rbind, image_rows)

# Check dimensions (rows = number of images, columns = total pixels * 3)
dim(M)
```


# Part A

As we compute the small var-cov matrix, the principal components are representing the variance among images. If we were computing the var-cov matrix in the regular way, we would be representing the variance in the pixels. Anyways we obtain the same nonzero eigenvalues.

```{r}
#compute_pca <- function(data) {
  # Compute mean
#  mean_m <- colMeans(data)
  
  # Subtract the mean from each row
#  centered_matrix <- sweep(data, 2, mean_m, FUN = "-")

#  n <- nrow(centered_matrix)
#  var_cov_small <- (1 / (n - 1)) * (centered_matrix %*% t(centered_matrix))
#  eigen_dec <- eigen(var_cov_small)
  
#  V <- t(centered_matrix) %*% eigen_dec$vectors
#  V <- apply(V, 2, function(v) v / sqrt(sum(v^2)))
  
  
  
#  return(list(mean_obs = mean_m, P = eigen_dec$vectors, D = eigen_dec$values, V=V))
#}

compute_pca <- function(data) {
  # Compute mean
  mean_m <- colMeans(data)
  
  # Subtract the mean from each row
  centered_matrix <- sweep(data, 2, mean_m, FUN = "-")

  n <- nrow(centered_matrix)
  var_cov_small <- (1 / (n - 1)) * (centered_matrix %*% t(centered_matrix))
  eigen_dec <- eigen(var_cov_small)
  
  P <- t(centered_matrix) %*% eigen_dec$vectors
  P <- apply(P, 2, function(p) p / sqrt(sum(p^2)))
  
  D <- eigen_dec$values / sum(eigen_dec$values)

  return(list(mean_obs = mean_m, P = P, D = D, E = eigen_dec$values))
}

pca_results <- compute_pca(M)

mean_obs <- pca_results$mean_obs
P <- pca_results$P #eigenvectors in pixel space normalized #image space
D <- pca_results$D #variance explained by eigenvalue
E <- pca_results$E #eigenvalues
#V <- pca_results$V #eigenvectors in pixel space normalized
```



Let's get the projection of the training images in the pca space

```{r}
#Y <- centered_matrix %*% V
Y <- sweep(M, 2, mean_obs, FUN = "-") %*% P
```

Visualize the `pc` component of the `image_index` image

```{r}
visualize_pc <- function(image_index, pc, mean_obs, P, Y, img_height = 200, img_width = 180) {
  # Extract the first principal component
  p1 <- P[,pc]  # First principal component (size p)
  
  # Get the projection of the specific image onto PC1
  y1 <- Y[image_index, 1]  # First coordinate in PCA space
  
  # Reconstruct only PC1 contribution
  x_pc1 <- y1 * p1 + mean_obs
  
  # Reshape into image dimensions
  image_matrix <- array(x_pc1, dim = c(img_height, img_width, 3))
  
  # Plot the PC1 contribution as an image
  return(image_matrix)
  
}

# Example: Visualizing the PC1 contribution for image x
image_matrix <- visualize_pc(1,1, mean_obs, P, Y)
OpenImageR::imageShow(image_matrix)
```

```{r}
#OpenImageR::writeImage(image_matrix, "output_image.png")
#utils::browseURL("output_image.png")
```


```{r}
library(plotly)

plot_pca_3d_interactive <- function(Y, image_ids) {
  df <- data.frame(PC1 = Y[,1], PC2 = Y[,2], PC3 = Y[,3], ID = factor(image_ids))

  plot_ly(df, x = ~PC1, y = ~PC2, z = ~PC3, color = ~ID, text = ~paste("ID:", ID),
          type = "scatter3d", mode = "markers") %>%
    layout(title = "PCA Projection (PC1 vs PC2 vs PC3)")
}

# Call the function to plot interactively
plot_pca_3d_interactive(Y, image_ids)

```

# Knn

1. Take the image to classify and compute the distance to all the other images.
2. Sort the distances by ascending order.
3. Take the k closest samples and the id corresponding to it. 
4. The class is the majority class among the closest neighbors.
5. Take the average distance of k nearest neighbors and if is larger than a threshold we consider that the image does not belong to the dataset.

"The best recognition results were achieved using
the following distance measures: simplified Mahalanobis, weighted angle-based distance, proposed modified SSE-based distance, angle-based distance between whitened feature vectors."



```{r}
project_image <- function(image_vector, mean_obs, P) {
  centered_image <- image_vector - mean_obs
  return(t(P) %*% centered_image)
}

#new_image_vector <- as.vector(OpenImageR::readImage(image_files[1]))
#y_new <- project_image(new_image_vector, mean_obs, V)

# Computes the distance between 2 vectors. D is the eigenvalue list, required for some metrics. 
compute_distance <- function(x, y, E, metric) {
    
    if (metric == "simplified_mahalanobis") {
      alpha <- 0.25
      z <- sqrt(pmax(0, E / (E + alpha^2)))
      return(-sum(z * x * y))
      
    } else if (metric == "weighted_angle") {
      z <- sqrt(pmax(0, 1 / E))
      return(-sum(z * x * y) / sqrt(sum(x^2) * sum(y^2)))
      
    } else if (metric == "modified_sse") {
      return(sum((x - y)^2) / (sum(x^2) * sum(y^2)))
      
    } else {
      stop("Invalid metric. Choose from 'simplified_mahalanobis', 'weighted_angle', or 'modified_sse'.")
    }
}

knn_classifier <- function(k, threshold, y_new, Y, image_ids, metric, E){
  #cat("length(y_new): ", length(y_new), '\n')
  #cat("dim(Y): ", dim(Y), '\n')
  # Compute distances of y_new with all rows in Y.
  #if (!is.matrix(y_new)) {
  #  y_new <- matrix(y_new, nrow = 1)  # Force y_new to always be a matrix
  #}
  distances <- apply(Y, 1, function(y) compute_distance(y, y_new, E, metric) )
  dist_df <- data.frame(ID = image_ids, Distance = distances)
  #cat("Distances computed: ", distances)
  # Sort the distance in ascending order
  dist_df <- dist_df[order(dist_df$Distance), ]

  # Take the first k distances
  k_nearest <- head(dist_df, k)
  #print(k_nearest)
  
  # Average distance. If distance is larger than threshold return 0. Else continue
  #distance <- mean(k_nearest$Distance) # Doesn't make sense in similarity metrics that can have negative values or ranges that go   from negatives to positive. Averaging positive and negative values might cancel out the real distance.
  
  # Min distance: If the closest/most similar, is too far, the rest will be farther.
  distance <- min(k_nearest$Distance)
  #cat("Min distance of the ", k, " closest images is: ", distance, "(",metric, ")\n")
  #cat("Threshold: ", threshold, "\n")
  #cat("Is distance bigger than threshold? ", distance > threshold, "\n")
  if (distance > threshold) {
    return(0)
  }
  
  # value count of the ids. Return the majority class.
  id_counts <- table(k_nearest$ID)
  majority_id <- as.numeric(names(which.max(id_counts)))
  return(majority_id)
}
```


# Parameter selection

```{r}
create_random_splits_by_image <- function(image_ids, percent_test = 0.3, num_splits = 5, num_people_to_exclude = 1) {
  set.seed(1)
  unique_people <- unique(image_ids)  # Get unique class labels
  
  splits <- lapply(1:num_splits, function(i) {
    
    # Randomly select people to exclude from train
    excluded_people <- sample(unique_people, num_people_to_exclude)
    
    # Get indices of images belonging to excluded people
    excluded_indices <- which(image_ids %in% excluded_people)
    
    # Sample test images from the remaining people
    remaining_images <- setdiff(names(image_ids), names(image_ids)[excluded_indices])  # Remove excluded images
    test_images <- sample(remaining_images, round(length(remaining_images) * percent_test))
    
    # Get test and train indices
    test_indices <- which(names(image_ids) %in% test_images)  # Normal test split
    test_indices <- unique(c(test_indices, excluded_indices))  # Force excluded images into the test set
    train_indices <- setdiff(seq_along(image_ids), test_indices)  # Remaining are train
    
    cat("\nExcluded people: ", paste(excluded_people, collapse = ", "), "\n")
    cat("length test: ", length(test_indices), "\nlength train: ", length(train_indices), "\n")
    
    # Extract class labels for train and test sets
    train_people <- unique(image_ids[train_indices])
    test_people <- unique(image_ids[test_indices])
    
    # Check if any class is in test but not in train
    missing_people <- setdiff(test_people, train_people)
    missing_people_indices <- which(image_ids %in% missing_people)
    
    if (length(missing_people) > 0) {
      cat("The following people are in the test set but not in the train set: ", paste(missing_people, collapse = ", "), '\n')
    }
    
    return(list(train = train_indices, test = test_indices, missing_people = missing_people_indices))
  })
  
  return(splits)
}

run_knn_classification <- function(Y_train, Y_test, image_ids_train, image_ids_test, 
                                   metrics, param_grid, fold, n_pc, E_pc, results) {
  
  for (metric in metrics) {
    if (!(metric %in% names(param_grid))) {
      stop(paste("Unknown metric:", metric))
    }
    
    for (k in param_grid$k_values) {
      for (threshold in param_grid[[metric]]) {
        
        cat("Testing Metric:", metric, "| k:", k, "| n_pc:", n_pc, "| threshold:", threshold, "\n")
        
        predictions <- sapply(1:nrow(Y_test), function(i) {
          knn_classifier(k, threshold, Y_test[i, ], Y_train, image_ids_train, metric, E_pc)
        })
        
        known_mask <- image_ids_test %in% image_ids_train  
        unknown_mask <- !image_ids_test %in% image_ids_train  
        
        known_accuracy <- ifelse(sum(known_mask) > 0, mean(predictions[known_mask] == image_ids_test[known_mask]), NA)
        unknown_accuracy <- ifelse(sum(unknown_mask) > 0, mean(predictions[unknown_mask] == 0), NA)
        balanced_accuracy <- mean(c(known_accuracy, unknown_accuracy), na.rm = TRUE)
        
        # Store results
        results <- rbind(results, data.frame(Fold = fold, n_pcs = n_pc, 
                                              Metric = metric, k = k, Threshold = threshold, 
                                              Known_Accuracy = known_accuracy, Unknown_Accuracy = unknown_accuracy,
                                              Balanced_Accuracy = balanced_accuracy))
      }
    }
  }
  return(results)
}

find_best_params <- function(M, image_ids, metrics, param_grid, num_folds = 5, num_people_to_exclude = 1, compute_pca = TRUE) {
  
  # Create random splits
  folds <- create_random_splits_by_image(image_ids, num_splits = num_folds, 
                                         num_people_to_exclude = num_people_to_exclude)
  results <- list()
  
  for (fold in seq_along(folds)) {
    test_indices <- folds[[fold]]$test
    train_indices <- folds[[fold]]$train
    
    cat("Fold:", fold, "\n")
    
    if (compute_pca) {
      cat("Computing PCA...\n")
      pca_results <- compute_pca(M[train_indices, ])
      
      mean_obs <- pca_results$mean_obs
      P <- pca_results$P
      E <- pca_results$E
      
      cat("PCA computed. Projecting data...\n")
      Y <- sweep(M, 2, mean_obs, FUN = "-") %*% P  # Project data
    } else {
      cat("Skipping PCA. Using original data...\n")
      Y <- M  # Work directly with the original data
    }
    
    cat("dim(Y):", dim(Y), "\n")
    
    # If we are not computing PCA, the only usable metric is 'modified_sse'. The others depend on the eigenvalues.
    if (!compute_pca) metrics <- c("modified_sse")
    
    # Define the dataset to use
    if (compute_pca) {
      n_pcs_list <- param_grid$n_pcs  # Iterate over principal components
    } else {
      n_pcs_list <- list(NA)  # Placeholder, as we don't loop over n_pcs
    }
    
    # Process with or without PCA
    if (compute_pca) {
      for (n_pc in n_pcs_list) {
        
        Y_pc <- Y[, 1:n_pc, drop = FALSE]  # Select principal components
        E_pc <- E[1:n_pc, drop = FALSE]    # Select corresponding eigenvalues
        Y_train <- Y_pc[train_indices, , drop = FALSE]
        Y_test <- Y_pc[test_indices, , drop = FALSE]
        
        image_ids_train <- image_ids[train_indices]
        image_ids_test <- image_ids[test_indices]
        
        results <- run_knn_classification(Y_train, Y_test, image_ids_train, image_ids_test, 
                               metrics, param_grid, fold, n_pc, E_pc, results)
      }
    } else {
      # No PCA: Use the entire dataset
      Y_train <- Y[train_indices, , drop = FALSE]
      Y_test <- Y[test_indices, , drop = FALSE]
      
      image_ids_train <- image_ids[train_indices]
      image_ids_test <- image_ids[test_indices]
      
      results <- run_knn_classification(Y_train, Y_test, image_ids_train, image_ids_test, 
                             metrics, param_grid, fold, n_pc = NA, E_pc = NULL, results)
    }
  }
  
  return(results)
}




get_best_params <- function(best_threshold=TRUE, param_grid_thresholds, M,image_ids, metrics, param_grid, num_folds = 5, num_people_to_exclude=1, compute_pca=TRUE){

  results <- find_best_params(M=M,image_ids=image_ids, metrics=c('modified_sse', 'simplified_mahalanobis', 'weighted_angle'), 
                                       param_grid=param_grid_thresholds, num_folds = num_folds, num_people_to_exclude=num_people_to_exclude, compute_pca=compute_pca)
  
  if(best_threshold){
    # Step 1: Get the best threshold per fold and metric
    best_thresholds_per_fold <- results %>%
      group_by(Fold, Metric) %>%
      slice_max(Balanced_Accuracy, n = 1, with_ties = FALSE) %>%  # Selects the best threshold per fold and metric
      select(Fold, Metric, Threshold, Balanced_Accuracy) %>%
      ungroup()
    
    #print(best_thresholds_per_fold)
    
    # Step 2: Compute the average threshold per metric
    average_best_thresholds <- best_thresholds_per_fold %>%
      group_by(Metric) %>%
      summarise(Average_Threshold = mean(Threshold, na.rm = TRUE)) %>%
      ungroup()
    
    #print(average_best_thresholds)
    
    # Convert to named vector for easy access
    best_thresholds_vector <- average_best_thresholds %>%
      pull(Average_Threshold, name = Metric)
    
    return(list(best_thresholds_per_fold=best_thresholds_per_fold,average_best_thresholds=average_best_thresholds, best_thresholds=best_thresholds_vector))
  }else{
    # Step 1: Get the best row per fold based on Balanced Accuracy
    best_per_fold <- results %>%
      group_by(Fold) %>%
      slice_max(Balanced_Accuracy, with_ties = FALSE)  # Selects the row with the highest Balanced Accuracy per fold
    
    print(best_per_fold)
    
    # Step 2: Compute the average k and n_pc by Metric
    average_k_npcs_by_metric <- best_per_fold %>%
      group_by(Metric) %>%
      summarise(
        Occurrences = n(),
        Average_k = mean(k, na.rm = TRUE),
        Average_n_pcs = mean(n_pcs, na.rm = TRUE),
        Average_Known_Accuracy = mean(Known_Accuracy, na.rm = TRUE),
        Average_Unknown_Accuracy = mean(Unknown_Accuracy, na.rm = TRUE),
        Average_Balanced_Accuracy = mean(Balanced_Accuracy, na.rm = TRUE)
      ) %>%
      ungroup()
    
    print(average_k_npcs_by_metric)
    
    # Step 3: Find the best metric (one with the highest average Balanced Accuracy)
    best_metric <- average_k_npcs_by_metric %>%
      slice_max(Occurrences, with_ties = FALSE) %>%
      pull(Metric)
    
    # Step 4: Compute the average k and n_pcs ONLY for the best metric
    final_avg_k <- average_k_npcs_by_metric %>%
      filter(Metric == best_metric) %>%
      pull(Average_k) %>%
      round()
    
    final_avg_n_pcs <- average_k_npcs_by_metric %>%
      filter(Metric == best_metric) %>%
      pull(Average_n_pcs) %>%
      round()
    
    return(list(best_per_fold=best_per_fold, average_k_npcs_by_metric=average_k_npcs_by_metric, best_metric = best_metric, final_avg_k = final_avg_k, final_avg_n_pcs = final_avg_n_pcs))
  }
  
}

```

## Threshold selection

```{r, include=FALSE}
if(COMPUTE_GRID_SEARCH){
  cat("Finding best threshold...\n")
  param_grid_thresholds <- list(
    n_pcs = c(30),  # Fixed n_pcs
    k_values = c(5),  # Fixed k
    modified_sse = seq(3e-5, 2.5e-4, by = 5e-6), # Threshold 3e-5
    simplified_mahalanobis = seq(-6000, -1500, by = 100),# Threshold -6000
    weighted_angle = seq(-0.07, -0.009, by = 0.005)# Threshold -0.07
  )

best_thresholds_pca_results <- get_best_params(best_threshold=TRUE,param_grid_thresholds, M,image_ids=image_ids, metrics=c('modified_sse', 'simplified_mahalanobis', 'weighted_angle'), param_grid=param_grid_thresholds, num_folds = 15, num_people_to_exclude=2, compute_pca=TRUE)

saveRDS(best_thresholds_pca_results, "best_thresholds_pca_results.rds")
}
```

```{r}
readRDS("best_thresholds_pca_results.rds")
```


## Metric, k, n_pcs selection


```{r, include=FALSE}
if(COMPUTE_GRID_SEARCH){
  cat("Finding best params...\n")
  best_thresholds_pca_results <- readRDS("best_thresholds_pca_results.rds")
  best_thresholds_pca <- best_thresholds_pca_results$best_thresholds
  
  param_grid_others <- list(
    n_pcs = seq(10, 30, by=1),
    #n_pcs = c(4),
    k_values = seq(1, 10, by=1),
    #k_values = c(1),
    modified_sse = c(best_thresholds_pca["modified_sse"]),
    simplified_mahalanobis = c(best_thresholds_pca["simplified_mahalanobis"]),
    weighted_angle = c(best_thresholds_pca["weighted_angle"])
  )
  
  best_params_pca <- get_best_params(best_threshold=FALSE,param_grid_others, M,image_ids=image_ids, metrics=c('modified_sse', 'simplified_mahalanobis', 'weighted_angle'), param_grid=param_grid_thresholds, num_folds = 15, num_people_to_exclude=2, compute_pca=TRUE)
  
  saveRDS(best_params_pca, "best_params_pca.rds")
}
```

```{r}
best_params_pca <- readRDS("best_params_pca.rds")
best_params_pca
```


# Compare PCA vs Original image representation

## Find best parameters original image representation.

### Threshold selection


```{r, include=FALSE}
if(COMPUTE_GRID_SEARCH){
  cat("Finding best parameters...\n")
  param_grid_thresholds <- list(
    n_pcs = c(30),  # Fixed n_pcs
    k_values = c(5),  # Fixed k
    modified_sse = seq(3e-5, 2.5e-4, by = 5e-6), # Threshold 3e-5
    simplified_mahalanobis = seq(-6000, -1500, by = 100),# Threshold -6000
    weighted_angle = seq(-0.07, -0.009, by = 0.005)# Threshold -0.07
  )
  
  best_thresholds_no_pca_results <- get_best_params(best_threshold=TRUE,param_grid_thresholds, M,image_ids=image_ids, metrics=c('modified_sse', 'simplified_mahalanobis', 'weighted_angle'), param_grid=param_grid_thresholds, num_folds = 5, num_people_to_exclude=2, compute_pca=FALSE)
  
  saveRDS(best_thresholds_no_pca_results, "best_thresholds_no_pca_results.rds")
}
```



### Metric, k, n_pcs selection

```{r, include=FALSE}
if(COMPUTE_GRID_SEARCH){
  cat("Finding best parameters...\n")
  best_thresholds_no_pca_results <- readRDS("best_thresholds_no_pca_results.rds")
  best_thresholds_no_pca <- best_thresholds_no_pca_results$best_thresholds
  
  param_grid_others <- list(
    n_pcs = seq(10, 30, by=1),
    #n_pcs = c(4),
    k_values = seq(1, 10, by=1),
    #k_values = c(1),
    modified_sse = c(best_thresholds_no_pca["modified_sse"]),
    simplified_mahalanobis = c(best_thresholds_no_pca["simplified_mahalanobis"]),
    weighted_angle = c(best_thresholds_no_pca["weighted_angle"])
  )
  
  best_params_no_pca <- get_best_params(best_threshold=FALSE,param_grid_others, M,image_ids=image_ids, metrics=c('modified_sse', 'simplified_mahalanobis', 'weighted_angle'), param_grid=param_grid_thresholds, num_folds = 5, num_people_to_exclude=2, compute_pca=FALSE)
  
  saveRDS(best_params_no_pca, "best_params_no_pca.rds")
}
```

```{r}
best_params_no_pca <- readRDS("best_params_no_pca.rds")
best_params_no_pca
```



