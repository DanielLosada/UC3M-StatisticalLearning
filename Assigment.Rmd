---
title: "Assigment"
output: html_document
date: "2025-02-25"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
install.packages("archive")
install.packages("OpenImageR")
```
```{r}
library(archive)
```


# Input data

```{r}
# Specify the file path
rar_file <- "Training.rar"

# Extract the contents
#unpacked_files <- archive::archive_extract(rar_file)
try(archive_extract("Training.rar"), silent = TRUE)
```


```{r}
get_sorted_filenames <- function(){
  # Get all .jpg files
  image_files <- list.files("Training", pattern = "\\.jpg$", full.names = TRUE)
  
  
  extract_id <- function(filename) {
    matches <- regmatches(basename(filename), regexpr("[0-9]+", basename(filename)))
    return(as.numeric(matches))  # Convert to numeric
  }
  
  sorted_indices <- order(sapply(image_files, extract_id))
  image_files <- image_files[sorted_indices]
  return(image_files)
  }
```

# Extract numeric ID from filenames (assumes ID appears before letters)
extract_id <- function(filename) {
  matches <- regmatches(filename, regexpr("[0-9]+", basename(filename)))
  return(as.numeric(matches))  # Convert to numeric
}

# Sort by extracted ID
sorted_indices <- order(sapply(image_files, extract_id))
image_files <- image_files[sorted_indices]  # Reorder image list


```{r}
# Get all .jpg files in the Training folder
image_files <- get_sorted_filenames()
#Remove the files
image_files <- image_files[!image_files %in% c("Training/1AT.jpg", "Training/3BT.jpg")]

image_ids <- sapply(image_files, extract_id)

image_rows  <- list()
for (file in image_files) {
  img <- OpenImageR::readImage(file)  # Load image
  
  # Flatten RGB channels and concatenate into a single row
  red <- as.vector(img[,,1])  # Flatten red channel
  green <- as.vector(img[,,2]) # Flatten green channel
  blue <- as.vector(img[,,3])  # Flatten blue channel
  
  # Combine R, G, B into one row and store it
  image_rows[[file]] <- c(red, green, blue)
}

# Convert the list of rows into a matrix
M <- do.call(rbind, image_rows)

# Check dimensions (rows = number of images, columns = total pixels * 3)
dim(M)
```



# Part A

As we compute the small var-cov matrix, the principal components are representing the variance among images. If we were computing the var-cov matrix in the regular way, we would be representing the variance in the pixels. Anyways we obtain the same nonzero eigenvalues.

```{r}
compute_pca <- function(data) {
  # Compute mean
  mean_m <- colMeans(data)
  
  # Subtract the mean from each row
  centered_matrix <- sweep(data, 2, mean_m, FUN = "-")

  n <- nrow(centered_matrix)
  var_cov_small <- (1 / (n - 1)) * (centered_matrix %*% t(centered_matrix))
  eigen_dec <- eigen(var_cov_small)
  
  V <- t(centered_matrix) %*% eigen_dec$vectors
  V <- apply(V, 2, function(v) v / sqrt(sum(v^2)))
  
  return(list(mean_obs = mean_m, P = eigen_dec$vectors, D = eigen_dec$values, V=V))
}

pca_results <- compute_pca(M)

mean_obs <- pca_results$mean_obs
P <- pca_results$P #eigenvectors in image space
D <- pca_results$D #eigenvalues
V <- pca_results$V #eigenvectors in pixel space normalized
```

# Variance explained by each component
```{r}
for (i in seq_along(D)) {
  cat("Principal component ", i, " explains ",D[i] / sum(D)*100, "% of the variance.\n")
}
```


Let's get the projection of the training images in the pca space

```{r}
#Y <- centered_matrix %*% V
Y <- sweep(M, 2, mean_obs, FUN = "-") %*% V
```

Visualize the `pc` component of the `image_index` image

```{r}
visualize_pc <- function(image_index, pc, mean_obs, V, Y, img_height = 200, img_width = 180) {
  # Extract the first principal component
  V1 <- V[,pc]  # First principal component (size p)
  
  # Get the projection of the specific image onto PC1
  y1 <- Y[image_index, 1]  # First coordinate in PCA space
  
  # Reconstruct only PC1 contribution
  x_pc1 <- y1 * V1 + mean_obs
  
  # Reshape into image dimensions
  image_matrix <- array(x_pc1, dim = c(img_height, img_width, 3))
  
  # Plot the PC1 contribution as an image
  return(image_matrix)
  
}

# Example: Visualizing the PC1 contribution for image x
image_matrix <- visualize_pc(1,1, mean_obs, V, Y)
OpenImageR::imageShow(image_matrix)
```

```{r}
OpenImageR::writeImage(image_matrix, "output_image.png")
utils::browseURL("output_image.png")
```


```{r}
#project_image <- function(image_vector, mean_obs, V) {
#  centered_image <- image_vector - mean_obs
#  return(t(V) %*% centered_image)
#}

#new_image_vector <- as.vector(OpenImageR::readImage(image_files[1]))
#y_new <- project_image(new_image_vector, mean_obs, V)
```


```{r}
library(plotly)

plot_pca_3d_interactive <- function(Y, image_ids) {
  df <- data.frame(PC1 = Y[,1], PC2 = Y[,2], PC3 = Y[,3], ID = factor(image_ids))

  plot_ly(df, x = ~PC1, y = ~PC2, z = ~PC3, color = ~ID, text = ~paste("ID:", ID),
          type = "scatter3d", mode = "markers") %>%
    layout(title = "PCA Projection (PC1 vs PC2 vs PC3)")
}

# Call the function to plot interactively
plot_pca_3d_interactive(Y, image_ids)

```

# Knn

1. Take the image to classify and compute the distance to all the other images.
2. Sort the distances by ascending order.
3. Take the k closest samples and the id corresponding to it. 
4. The class is the majority class among the closest neighbors.
5. Take the average distance of k nearest neighbors and if is larger than a threshold we consider that the image does not belong to the dataset.

"The best recognition results were achieved using
the following distance measures: simplified Mahalanobis, weighted angle-based distance, proposed modified SSE-based distance, angle-based distance between whitened feature vectors."



```{r}
project_image <- function(image_vector, mean_obs, V) {
  centered_image <- image_vector - mean_obs
  return(t(V) %*% centered_image)
}

#new_image_vector <- as.vector(OpenImageR::readImage(image_files[1]))
#y_new <- project_image(new_image_vector, mean_obs, V)

# Computes the distance between 2 vectors. D is the eigenvalue list, required for some metrics. 
compute_distance <- function(x, y, D, metric) {
    
    if (metric == "simplified_mahalanobis") {
      alpha <- 0.25
      z <- sqrt(pmax(0, D / (D + alpha^2)))
      return(-sum(z * x * y))
      
    } else if (metric == "weighted_angle") {
      z <- sqrt(pmax(0, 1 / D))
      return(-sum(z * x * y) / sqrt(sum(x^2) * sum(y^2)))
      
    } else if (metric == "modified_sse") {
      return(sum((x - y)^2) / (sum(x^2) * sum(y^2)))
      
    } else {
      stop("Invalid metric. Choose from 'simplified_mahalanobis', 'weighted_angle', or 'modified_sse'.")
    }
}

knn_classifier <- function(k, threshold, y_new, Y, image_ids, metric, D){
  # Compute distances of y_new with all rows in Y.
  distances <- apply(Y, 1, function(y) compute_distance(y, y_new, D, metric) )
  dist_df <- data.frame(ID = image_ids, Distance = distances)
  
  # Sort the distance in ascending order
  dist_df <- dist_df[order(dist_df$Distance), ]
  
  # Take the first k distances
  k_nearest <- head(dist_df, k)
  print(k_nearest)
  # Average distance. If distance is larger than threshold return 0. Else continue
  avg_distance <- mean(k_nearest$Distance)
  cat("Average distance of the ", k, " closest images is: ", avg_distance, "(",metric, ")\n")
  if (avg_distance > threshold) {
    return(0)
  }
  
  # value count of the ids. Return the majority class.
  id_counts <- table(k_nearest$ID)
  majority_id <- as.numeric(names(which.max(id_counts)))
  return(majority_id)
}
```

```{r}
#Test with "Training/1AT.jpg", "Training/3BT.jpg"
new_image_vector <- as.vector(OpenImageR::readImage("Training/19BT.jpg"))
y_new <- project_image(new_image_vector, mean_obs, V)

knn_classifier(5, 100, y_new, Y, image_ids, 'weighted_angle', D)
```



# Parameter selection

1. Perform a k-fold cross-validation to decide the k, the treshold, and the PCs taken, and similarity metric. We need to define a metric to maximize.

```{r}
'''
compute_avg_within_distances <- function(Y, image_ids) {
  unique_ids <- unique(image_ids)  # Get unique person IDs
  avg_distances <- numeric(length(unique_ids))  # Store results
  
  for (i in seq_along(unique_ids)) {
    person_id <- unique_ids[i]
    indices <- which(image_ids == person_id)  # Find images of this person
    
    if (length(indices) > 1) {
      # Compute all pairwise distances
      pairwise_distances <- as.matrix(dist(Y[indices, ]))
      avg_distances[i] <- mean(pairwise_distances[lower.tri(pairwise_distances)])  # Average of lower triangle
    } else {
      avg_distances[i] <- NA  # If only one image, no distance can be computed
    }
  }
  
  return(data.frame(Person = unique_ids, Avg_Distance = avg_distances))
}

image_ids <- sapply(image_files, extract_id)
# Compute average distances for each person
within_person_distances <- compute_avg_within_distances(Y, image_ids)
'''
```



